{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cognitive_load_estimation_ELL788.ipynb",
      "provenance": [],
      "mount_file_id": "1opF_JfnZ1xukdGsE9rbVg2F7787poqO4",
      "authorship_tag": "ABX9TyNJxykbvV9P5zh/DFdagWzP"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import the Libraries"
      ],
      "metadata": {
        "id": "le4lmEQ5-BcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from scipy.signal import butter, lfilter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.signal\n",
        "# from numpy.core.multiarray import ndarray\n",
        "# from scipy import signal\n",
        "# import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# import seaborn as sn\n",
        "import io\n",
        "import matplotlib\n",
        "import  matplotlib.pyplot as plt\n",
        "from scipy import signal\n",
        "import numpy as np\n",
        "import scipy.signal\n",
        "from scipy.signal import chirp, find_peaks, peak_widths, peak_prominences\n",
        "from numpy import mean, median, std, percentile, fft, abs, argmax\n",
        "from scipy.stats import norm, kurtosis, skew\n",
        "import numpy as np\n",
        "import scipy.signal\n",
        "from scipy.signal import chirp, find_peaks, peak_widths, peak_prominences\n",
        "from statsmodels.tsa import stattools\n",
        "import math\n",
        "from sklearn import linear_model, neighbors\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import preprocessing\n",
        "from scipy.stats import entropy\n",
        "from scipy.fft import fft, ifft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUiZZish-Hmo",
        "outputId": "7fd29288-ca7f-4e8c-8e0a-fa9a745e2087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('/content/Normalizedfeatures.csv')\n",
        "attributes=f.readline()\n",
        "X = []\n",
        "y = []\n",
        "for line in f:\n",
        "    line = line.rstrip().split(',')\n",
        "    l = [float(i) for i in line]\n",
        "    X.append(l[:-1])\n",
        "    y.append(l[-1])\n",
        "    \n",
        "X = np.asarray(X)\n",
        "y = np.asarray(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "r4v6FW2M-MKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Selection using P value"
      ],
      "metadata": {
        "id": "-oogGxPC-Bky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dCXwhW0IdPR",
        "outputId": "5e160d5b-07d1-435e-a876-804eb66e8363"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2568, 174)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "# print(X_train)\n",
        "from sklearn.feature_selection import chi2\n",
        "chi,p_value=chi2(X,y)\n",
        "import pandas as pd\n",
        "p_values=pd.Series(p_value)\n",
        "# p_values.index=X_train\n",
        "print(\"p_value\",p_values)\n",
        "# print(\"chi_square\",chi)\n",
        "print(p_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jfUxPWsIerF",
        "outputId": "1c8886bd-5e86-4bfd-addd-20f1ed4ef3d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p_value 0      1.023277e-50\n",
            "1      9.963228e-01\n",
            "2      9.701008e-96\n",
            "3      4.717678e-67\n",
            "4      8.217080e-25\n",
            "           ...     \n",
            "169    6.105339e-05\n",
            "170    9.770459e-02\n",
            "171    1.176904e-03\n",
            "172    7.584845e-06\n",
            "173    1.471996e-04\n",
            "Length: 174, dtype: float64\n",
            "[1.02327692e-50 9.96322767e-01 9.70100831e-96 4.71767822e-67\n",
            " 8.21707992e-25 1.43406372e-15 3.68725863e-03 1.07848841e-64\n",
            " 7.39380857e-09 3.81693955e-01 3.08202735e-72 2.16878447e-77\n",
            " 9.61734278e-06 9.72274363e-37 1.74500534e-34 3.69315742e-54\n",
            " 8.74581411e-03 5.84218045e-03 3.19469358e-06 6.11968878e-03\n",
            " 9.32304252e-01 4.21537891e-55 8.70683995e-01 9.37373254e-01\n",
            " 2.54670652e-74 6.30797005e-91 5.32244429e-96 8.71127050e-01\n",
            " 8.78892734e-01 5.18149447e-05 8.67335229e-01 9.36659163e-01\n",
            " 7.48880044e-41 2.44827783e-75 4.17424011e-82 8.67521061e-01\n",
            " 9.43716542e-01 6.96858580e-47 8.70681710e-01 9.35976341e-01\n",
            " 9.46350274e-74 4.20778476e-91 4.07002372e-96 8.71096229e-01\n",
            " 9.15974918e-01 5.89900006e-52 8.70128153e-01 9.36562277e-01\n",
            " 3.50071410e-74 2.82316256e-91 2.27504601e-96 8.70526892e-01\n",
            " 8.92626139e-01 9.96565346e-65 8.69552420e-01 9.36768094e-01\n",
            " 2.89828206e-73 2.91204937e-91 2.26010411e-96 8.69921610e-01\n",
            " 9.35761964e-01 3.52502756e-62 8.68551823e-01 9.36456365e-01\n",
            " 2.89056084e-74 3.39897184e-91 3.86210474e-96 8.68864251e-01\n",
            " 8.02114076e-01 1.01820914e-65 8.70028213e-01 9.37227716e-01\n",
            " 1.59761836e-74 3.75789468e-92 2.99432066e-97 8.70426549e-01\n",
            " 7.45462504e-01 2.28488296e-47 8.78925796e-01 9.37660790e-01\n",
            " 1.38350667e-74 2.85156430e-91 2.64916478e-96 8.79795950e-01\n",
            " 8.48103387e-01 3.66954018e-19 8.82140040e-01 9.38487629e-01\n",
            " 1.12608543e-71 1.57406370e-89 4.81599574e-95 8.83172286e-01\n",
            " 8.76008399e-01 9.40318973e-21 8.80509100e-01 9.37670324e-01\n",
            " 6.62056731e-71 1.11191692e-89 3.01286760e-95 8.81456884e-01\n",
            " 7.79293377e-01 1.02949354e-17 8.82607306e-01 9.38428136e-01\n",
            " 1.28336336e-69 2.94016885e-88 5.66331674e-94 8.83662457e-01\n",
            " 4.99979998e-02 4.28641408e-43 8.99001958e-01 9.35992332e-01\n",
            " 1.90722761e-66 3.67775273e-88 4.84552647e-94 9.00885068e-01\n",
            " 9.46203896e-01 6.16084489e-11 8.88192304e-01 9.37123838e-01\n",
            " 6.39377874e-73 3.89826280e-91 2.70676308e-96 8.89627057e-01\n",
            " 8.36535133e-01 1.35048720e-17 8.83800428e-01 9.39530606e-01\n",
            " 1.85624928e-71 8.65111199e-90 3.88368521e-95 8.85009798e-01\n",
            " 6.47578472e-04 4.28268492e-07 6.83968134e-02 1.56583845e-36\n",
            " 1.08368151e-30 1.14043283e-17 1.73055992e-04 9.39762399e-08\n",
            " 1.57156696e-02 5.30594831e-23 1.02295064e-19 5.11145494e-04\n",
            " 4.58895816e-30 3.31517471e-22 2.01214035e-11 2.11290769e-25\n",
            " 3.12247733e-21 1.82542480e-12 1.51820302e-32 4.29598942e-25\n",
            " 7.84602979e-14 1.01255991e-12 4.30520811e-10 6.56036103e-01\n",
            " 2.59614268e-12 1.70070502e-08 1.46984921e-06 8.35746567e-09\n",
            " 9.83814718e-07 5.86705721e-07 5.11180335e-09 6.94038266e-07\n",
            " 1.82767482e-07 6.07554780e-10 2.30064010e-09 3.73795151e-10\n",
            " 3.47150663e-02 6.10533882e-05 9.77045911e-02 1.17690396e-03\n",
            " 7.58484504e-06 1.47199647e-04]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s=[]\n",
        "s=np.argsort(p_values)"
      ],
      "metadata": {
        "id": "_3pFCBx6Igi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f=[]\n",
        "f=s[:90,]\n"
      ],
      "metadata": {
        "id": "4TrUswSPIjKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X1=X[:,f]\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LK6NSwgjIk5b",
        "outputId": "13fa5330-c62f-4a9d-a20b-2b583c1ec806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. ... 3. 3. 3.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "iLLuvQkJIpqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train classifiers using K-fold cross validation"
      ],
      "metadata": {
        "id": "ISFspFjVPzhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_scores = []\n",
        "svml_score=[]\n",
        "svmr_score=[]\n",
        "dt=[]\n",
        "k=[]\n",
        "\n",
        "best_svr= RandomForestClassifier(criterion='entropy', max_depth=6, random_state=0)\n",
        "clf12 = SVC(C=100, kernel='linear')\n",
        "clf1 = SVC(C=100, kernel='rbf')\n",
        "d=DecisionTreeClassifier(criterion='entropy',max_depth=3, max_leaf_nodes=10, random_state=0)\n",
        "knn = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "cv = KFold(n_splits=7)\n",
        "for train_index, test_index in cv.split(X1):\n",
        "\n",
        "\n",
        "    X_train, X_test, y_train, y_test = X1[train_index], X1[test_index], y[train_index], y[test_index]\n",
        "\n",
        "    best_svr.fit(X_train, y_train)\n",
        "    clf12.fit(X_train, y_train)\n",
        "    clf1.fit(X_train, y_train)\n",
        "    d.fit(X_train, y_train)\n",
        "    knn.fit(X_train,y_train)\n",
        "\n",
        "    rf_scores.append(best_svr.score(X_test, y_test))\n",
        "    svml_score.append(clf12.score(X_test, y_test))\n",
        "    svmr_score.append(clf1.score(X_test, y_test))\n",
        "    dt.append(d.score(X_test, y_test))\n",
        "    k.append(knn.score(X_test, y_test))\n",
        "#\n",
        "print(\"random_forest\", rf_scores)\n",
        "print(np.mean(rf_scores))\n",
        "print(\"svm\", svml_score)\n",
        "print(np.mean(svml_score))\n",
        "print(\"svmr\", svmr_score)\n",
        "print(np.mean(svmr_score))\n",
        "print(\"dt\",dt)\n",
        "print(np.mean(dt))\n",
        "print(\"knn\",k)\n",
        "print(np.mean(k))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sv9uYC5fIvYL",
        "outputId": "e005b167-aeb9-4023-930f-796742a85fce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "random_forest [0.7166212534059946, 0.7329700272479565, 0.5803814713896458, 0.7329700272479565, 0.6239782016348774, 0.7384196185286104, 0.7513661202185792]\n",
            "0.696672388524803\n",
            "svm [0.7166212534059946, 0.8528610354223434, 0.7029972752043597, 0.8365122615803815, 0.7983651226158038, 0.9182561307901907, 0.8907103825136612]\n",
            "0.8166176373618192\n",
            "svmr [0.7166212534059946, 0.8337874659400545, 0.6975476839237057, 0.8446866485013624, 0.8283378746594006, 0.9264305177111717, 0.9153005464480874]\n",
            "0.8232445700842538\n",
            "dt [0.7138964577656676, 0.5885558583106267, 0.4332425068119891, 0.6566757493188011, 0.5013623978201635, 0.5858310626702997, 0.5737704918032787]\n",
            "0.5790477892144038\n",
            "knn [0.7138964577656676, 0.8555858310626703, 0.7275204359673024, 0.8092643051771117, 0.7929155313351499, 0.9073569482288828, 0.9207650273224044]\n",
            "0.8181863624084557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Individual Train and Test Accuracy"
      ],
      "metadata": {
        "id": "WPBzgsYdQNWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score"
      ],
      "metadata": {
        "id": "0gmvoWWHKthl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size=0.25, random_state=42)\n",
        "clf = RandomForestClassifier(criterion='entropy', max_depth=4, random_state=0)\n",
        "clf.fit(X_train,y_train)\n",
        "Test_rf = clf.predict(X_test) #Predict the test result & returns 1-D array\n",
        "Test_accuracy=accuracy_score(y_true = y_test, y_pred = Test_rf)\n",
        "Train_rf= clf.predict(X_train)\n",
        "Train_accuracy=accuracy_score(y_true =y_train , y_pred = Train_rf)\n",
        "print(\"Train Accuracy of RF  {}\".format(Train_accuracy))\n",
        "print(\"Test Accuracy of RF   {}\".format(Test_accuracy))\n",
        "cm = confusion_matrix(y_test, Test_rf)\n",
        "print (\"Confusion matrix:\",cm)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(f1_score(y_test, y_pred, average=\"macro\"))\n",
        "print(precision_score(y_test, y_pred, average=\"macro\"))\n",
        "print(recall_score(y_test, y_pred, average=\"macro\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY37GcDJXOcR",
        "outputId": "3e854ee2-199f-4f1e-8a20-b8ad103fb763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy of RF  0.8613707165109035\n",
            "Test Accuracy of RF   0.8598130841121495\n",
            "Confusion matrix: [[ 93   0  11]\n",
            " [  0 163  66]\n",
            " [  0  13 296]]\n",
            "0.8723786329229991\n",
            "0.9065673490941588\n",
            "0.8546499882776221\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cli = [1,0.5,0.1,0.01,0.003,0.0003]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size=0.25, random_state=42)\n",
        "\n",
        "trainacc = np.array([])\n",
        "testacc = np.array([])\n",
        "for j in cli:         #iterating through different penalty values\n",
        "    LRmod = linear_model.LogisticRegression(penalty='l2', C=j)\n",
        "    LRmod.fit(X_train,y_train)\n",
        "    pred = LRmod.predict(X_test)\n",
        "    pred1 = LRmod.predict(X_train)\n",
        "    testac = accuracy_score(y_true = y_test, y_pred = pred)\n",
        "    trainac = accuracy_score(y_true = y_train, y_pred = pred1)\n",
        "    trainacc = np.append(trainacc,trainac)\n",
        "    testacc = np.append(testacc,testac)\n",
        "    print(\"Training Accuracy for penalty {}: {}\".format(j,trainac))\n",
        "    print(\"Testing Accuracy for penalty {}: {}\".format(j,testac))\n",
        "Accuracy_KNN = np.array([])\n",
        "Accuracy_knn_train=np.array([])\n",
        "rangeli = list(range(3,10))\n",
        "for i in rangeli:\n",
        "    knn = neighbors.KNeighborsClassifier(n_neighbors=i)\n",
        "    knn.fit(X_train,y_train)\n",
        "    predicted_knn = knn.predict(X_test)\n",
        "    predict_train=knn.predict(X_train)\n",
        "    Accuracy = accuracy_score(y_true = y_test, y_pred = predicted_knn)\n",
        "    Train_KnnAccuracy=accuracy_score(y_train,predict_train)\n",
        "    print('==========',i ,  Accuracy,\"Train_Acuracy : \",Train_KnnAccuracy)\n",
        "    Accuracy_KNN = np.append(Accuracy_KNN, Accuracy)\n",
        "    Accuracy_knn_train=np.append(Accuracy_knn_train,Train_KnnAccuracy)\n",
        "print(\"Test_Optimal K value is {} Train_Optimal k value is {}\".format(rangeli[np.argmax(Accuracy_KNN)],rangeli[np.argmax(Accuracy_knn_train)]))\n",
        "print(f\"Train Accuracy of optimum k value is : {np.max(Accuracy_knn_train)}\")\n",
        "print(\"Test Accuracy of Optimum K value is {}\".format(np.max(Accuracy_KNN)))\n",
        "Test1 = knn.predict(X_test)\n",
        "cm1 = confusion_matrix(y_test, Test1)\n",
        "print (\"Confusion matrix:\",cm1)\n",
        "y_pred = knn.predict(X_test)\n",
        "print(f1_score(y_test, y_pred, average=\"macro\"))\n",
        "print(precision_score(y_test, y_pred, average=\"macro\"))\n",
        "print(recall_score(y_test, y_pred, average=\"macro\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4m9fTCKOPxF",
        "outputId": "f8615458-aa64-4767-e769-d667204ecd72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy for penalty 1: 0.8660436137071651\n",
            "Testing Accuracy for penalty 1: 0.8722741433021807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy for penalty 0.5: 0.8572170301142263\n",
            "Testing Accuracy for penalty 0.5: 0.8629283489096573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy for penalty 0.1: 0.8037383177570093\n",
            "Testing Accuracy for penalty 0.1: 0.8006230529595015\n",
            "Training Accuracy for penalty 0.01: 0.7476635514018691\n",
            "Testing Accuracy for penalty 0.01: 0.7445482866043613\n",
            "Training Accuracy for penalty 0.003: 0.6593977154724818\n",
            "Testing Accuracy for penalty 0.003: 0.6557632398753894\n",
            "Training Accuracy for penalty 0.0003: 0.5960539979231568\n",
            "Testing Accuracy for penalty 0.0003: 0.5872274143302181\n",
            "========== 3 0.897196261682243 Train_Acuracy :  0.9470404984423676\n",
            "========== 4 0.897196261682243 Train_Acuracy :  0.9304257528556594\n",
            "========== 5 0.9065420560747663 Train_Acuracy :  0.9241952232606438\n",
            "========== 6 0.897196261682243 Train_Acuracy :  0.9174454828660437\n",
            "========== 7 0.8862928348909658 Train_Acuracy :  0.9127725856697819\n",
            "========== 8 0.8862928348909658 Train_Acuracy :  0.9075804776739356\n",
            "========== 9 0.883177570093458 Train_Acuracy :  0.9044652128764278\n",
            "Test_Optimal K value is 5 Train_Optimal k value is 3\n",
            "Train Accuracy of optimum k value is : 0.9470404984423676\n",
            "Test Accuracy of Optimum K value is 0.9065420560747663\n",
            "Confusion matrix: [[ 93   3   8]\n",
            " [  0 192  37]\n",
            " [  0  27 282]]\n",
            "0.894132043687852\n",
            "0.9090833953219275\n",
            "0.8817600253507746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf12 = SVC(C= 10, kernel='linear') #Loading the Data\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=1)\n",
        "print(f\"X_test size {X_test.shape} and X_train size:{X_train.shape}\")\n",
        "clf12.fit(X_train,y_train) #Train The Data\n",
        "Test_predsvm = clf12.predict(X_test) #Predict the test result & returns 1-D array\n",
        "Test_accuracy=accuracy_score(y_true = y_test, y_pred = Test_predsvm)\n",
        "Train_predsvm= clf12.predict(X_train)\n",
        "Train_accuracy=accuracy_score(y_true =y_train , y_pred = Train_predsvm)\n",
        "print(\"Train Accuracy of SVM  {}\".format(Train_accuracy))\n",
        "print(\"Test Accuracy of SVM   {}\".format(Test_accuracy))\n",
        "print(Train_predsvm)\n",
        "# plt.bar(np.array(range(0,100)),Test_predsvm[0:100])\n",
        "# plt.show()\n",
        "cm = confusion_matrix(y_test, Test_predsvm)\n",
        "print (\"Confusion matrix:\",cm)\n",
        "y_pred = clf12.predict(X_test)\n",
        "print(f1_score(y_test, y_pred, average=\"macro\"))\n",
        "print(precision_score(y_test, y_pred, average=\"macro\"))\n",
        "print(recall_score(y_test, y_pred, average=\"macro\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbT1KqXPKfAw",
        "outputId": "1efbfbc5-1edc-4bde-a647-38d7b86baca7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test size (514, 174) and X_train size:(2054, 174)\n",
            "Train Accuracy of SVM  0.9527750730282376\n",
            "Test Accuracy of SVM   0.9591439688715954\n",
            "[2. 3. 3. ... 3. 1. 2.]\n",
            "Confusion matrix: [[ 68   0   0]\n",
            " [  0 170  16]\n",
            " [  0   5 255]]\n",
            "0.9674267440829251\n",
            "0.9707959936742224\n",
            "0.9649159084642956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "clf1 = SVC(C=100, kernel='rbf') #Loading the Data\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=1)\n",
        "print(f\"X_test size {X_test.shape} and X_train size:{X_train.shape}\")\n",
        "clf1.fit(X_train,y_train) #Train The Data\n",
        "Test_predsvm = clf1.predict(X_test) #Predict the test result & returns 1-D array\n",
        "Test_accuracy=accuracy_score(y_true = y_test, y_pred = Test_predsvm)\n",
        "Train_predsvm= clf1.predict(X_train)\n",
        "Train_accuracy=accuracy_score(y_true =y_train , y_pred = Train_predsvm)\n",
        "print(\"Train Accuracy of SVM  {}\".format(Train_accuracy))\n",
        "print(\"Test Accuracy of SVM   {}\".format(Test_accuracy))\n",
        "print(Train_predsvm)\n",
        "# plt.bar(np.array(range(0,100)),Test_predsvm[0:100])\n",
        "# plt.show()\n",
        "cm = confusion_matrix(y_test, Test_predsvm)\n",
        "print (\"Confusion matrix:\",cm)\n",
        "y_pred = clf1.predict(X_test)\n",
        "print(f1_score(y_test, y_pred, average=\"macro\"))\n",
        "print(precision_score(y_test, y_pred, average=\"macro\"))\n",
        "print(recall_score(y_test, y_pred, average=\"macro\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xces_LJONTm0",
        "outputId": "a77fedef-7881-4f90-9bdb-e4a179316fd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test size (514, 174) and X_train size:(2054, 174)\n",
            "Train Accuracy of SVM  0.9741966893865628\n",
            "Test Accuracy of SVM   0.9747081712062257\n",
            "[2. 3. 3. ... 2. 1. 2.]\n",
            "Confusion matrix: [[ 68   0   0]\n",
            " [  1 176   9]\n",
            " [  0   3 257]]\n",
            "0.9780902011193051\n",
            "0.9783042944581112\n",
            "0.9782326992004412\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "print(f\"X_test size {X_test.shape} and X_train size:{X_train.shape}\")\n",
        "rank_classifier = DecisionTreeClassifier(criterion='entropy',max_depth=6, max_leaf_nodes=20, random_state=0)\n",
        "rank_classifier.fit(X_train,y_train)\n",
        "Predictions_train=rank_classifier.predict(X_train)\n",
        "Predictions_test = rank_classifier.predict(X_test)\n",
        "AccuracyTrain_DT=accuracy_score(y_train,Predictions_train)\n",
        "AcuuracyTest_DT=accuracy_score(y_test,Predictions_test)\n",
        "print(f\"Accuracy Score of DT for Training Data : {AccuracyTrain_DT} \\n Accuracy score of DT for Testing Data :{AcuuracyTest_DT}\")\n",
        "Test = rank_classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, Test)\n",
        "print (\"Confusion matrix:\",cm)\n",
        "y_pred = rank_classifier.predict(X_test)\n",
        "print(f1_score(y_test, y_pred, average=\"macro\"))\n",
        "print(precision_score(y_test, y_pred, average=\"macro\"))\n",
        "print(recall_score(y_test, y_pred, average=\"macro\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a8r2YAhNjTk",
        "outputId": "0465615b-beea-48b1-a1d0-f62eea4003ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test size (514, 174) and X_train size:(2054, 174)\n",
            "Accuracy Score of DT for Training Data : 0.8938656280428432 \n",
            " Accuracy score of DT for Testing Data :0.8696498054474708\n",
            "Confusion matrix: [[ 67   0   1]\n",
            " [  3 127  56]\n",
            " [  3   4 253]]\n",
            "0.8797785792758962\n",
            "0.9011343000970363\n",
            "0.8803889132162377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "clf2 = MLPClassifier(alpha=5,hidden_layer_sizes=(300, 6), random_state=1,solver='lbfgs')\n",
        "sgd = MLPClassifier(alpha=5,hidden_layer_sizes=(300, 6), random_state=1, solver ='sgd',max_iter=500 )\n",
        "clf2.fit(X_train,y_train)\n",
        "sgd.fit(X_train,y_train)\n",
        "pred = clf2.predict(X_test)\n",
        "predt = clf2.predict(X_train)\n",
        "TeAccuracy = accuracy_score(y_true = y_test, y_pred = pred)\n",
        "TrAccuracy = accuracy_score(y_true = y_train, y_pred = predt)\n",
        "y_pred = clf2.predict(X_test)\n",
        "Test = clf2.predict(X_test)\n",
        "cm = confusion_matrix(y_test, Test)\n",
        "print (\"Confusion matrix:\",cm)\n",
        "print(f1_score(y_test, y_pred, average=\"macro\"))\n",
        "print(precision_score(y_test, y_pred, average=\"macro\"))\n",
        "print(recall_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Training Accuracy in Neural Network: {}\".format(TrAccuracy))\n",
        "print(\"Testing Accuracy in Neural Network: {}\".format(TeAccuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBRpiEwKN1t5",
        "outputId": "d78858d4-9558-457c-ba60-57c3649461a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix: [[ 64   4   0]\n",
            " [  1 173  12]\n",
            " [  0   6 254]]\n",
            "0.9552849531373231\n",
            "0.9616192646391094\n",
            "0.9494023581310108\n",
            "Training Accuracy in Neural Network: 0.9313534566699123\n",
            "Testing Accuracy in Neural Network: 0.9552529182879378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    }
  ]
}